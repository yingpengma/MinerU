import streamlit as st
import json
import time
from datetime import datetime
from rag_core import initialize_rag_system, get_reference_map

# ä¸ºå®ç°å¯è¿½æº¯æ€§è€Œæ–°å¢çš„ import
from llama_index.core import VectorStoreIndex, Settings
from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler
from llama_index.core.callbacks.schema import CBEventType, EventPayload

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="Mineru RAG System (é€æ˜ç‰ˆ)",
    page_icon="â›ï¸",
    layout="wide"
)

st.title("â›ï¸ Mineru RAG ç³»ç»Ÿ (é€æ˜ç‰ˆ)")
st.write("ä¸€ä¸ªå®Œå…¨é€æ˜çš„äº¤äº’å¼é—®ç­”ç³»ç»Ÿã€‚æ‚¨å°†çœ‹åˆ°ä»æé—®åˆ°å›ç­”çš„æ¯ä¸€ä¸ªå†…éƒ¨æ­¥éª¤ã€‚")

# --- STEP 1: åŠ è½½å¹¶ç¼“å­˜åº•å±‚çš„ã€ç¨³å®šçš„ vector_store ---
with st.spinner("æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿï¼ŒåŠ è½½æ¨¡å‹å’Œç´¢å¼•... è¯·ç¨å€™..."):
    vector_store = initialize_rag_system()
    reference_map = get_reference_map()

if vector_store is None:
    st.error("ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—ã€‚")
    st.stop()

# --- èŠå¤©ç•Œé¢ ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "æ‚¨å¥½ï¼æˆ‘å·²ç»å­¦ä¹ äº†æ‚¨çš„æ–‡æ¡£ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„ï¼Ÿ"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    with st.chat_message("assistant"):
        response_container = st.empty()
        
        # --- æœ€ç»ˆä¿®æ­£: éµå¾ªæœ€æ–°çš„ llama-index æ¨¡å¼ ---
        
        # a. ä¸ºæœ¬æ¬¡æŸ¥è¯¢åˆ›å»ºå…¨æ–°çš„è¿½è¸ªå™¨
        llama_debug = LlamaDebugHandler()
        callback_manager = CallbackManager([llama_debug])
        
        # b. å°†è¿½è¸ªå™¨è®¾ç½®åœ¨å…¨å±€ Settings å¯¹è±¡ä¸Š
        Settings.callback_manager = callback_manager
        
        # c. ä»ç¼“å­˜çš„ vector_store åŠ¨æ€åˆ›å»º indexï¼Œå®ƒä¼šè‡ªåŠ¨ç»§æ‰¿å…¨å±€ Settings
        index = VectorStoreIndex.from_vector_store(vector_store)
        
        # d. ä»æ–°é²œçš„ index åˆ›å»ºæŸ¥è¯¢å¼•æ“
        query_engine = index.as_query_engine(similarity_top_k=3)
        
        with st.status("æ­£åœ¨å¤„ç†æ‚¨çš„é—®é¢˜...", expanded=False) as status:
            status.write("1. åˆ†æé—®é¢˜å¹¶è°ƒç”¨ Embedding æ¨¡å‹...")
            response = query_engine.query(prompt)
            status.write("2. åœ¨ ChromaDB ä¸­æ‰§è¡Œå‘é‡æ£€ç´¢...")
            time.sleep(0.2)
            status.write("3. å°†æ£€ç´¢ç»“æœä¸é—®é¢˜æ•´åˆæˆæç¤ºè¯ (Prompt)...")
            time.sleep(0.2)
            status.write("4. è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) ç”Ÿæˆç­”æ¡ˆ...")
            time.sleep(0.2)
            status.update(label="ç­”æ¡ˆç”Ÿæˆå®Œæ¯•ï¼", state="complete")

        response_container.write(response.response)

        # --- å…¨æ–°: æ˜¾ç¤ºè¯¦ç»†ã€å¯ç”¨çš„å¯è¿½æº¯æµç¨‹ ---
        with st.expander("ğŸ” ç‚¹å‡»æŸ¥çœ‹æœ¬æ¬¡æŸ¥è¯¢çš„è¯¦ç»†æº¯æºæµç¨‹", expanded=True):
            event_pairs = llama_debug.get_event_pairs()
            if not event_pairs:
                st.warning("æœªèƒ½æ•è·åˆ°ä»»ä½•å¤„ç†äº‹ä»¶ã€‚")
            else:
                # --- NEW: Helper to get duration and format it ---
                def get_duration(etype):
                    pair = next((p for p in event_pairs if p[0].event_type == etype), None)
                    if pair:
                        # CRITICAL FIX 2: Use strptime for the custom timestamp format
                        time_format = "%m/%d/%Y, %H:%M:%S.%f"
                        start_time = datetime.strptime(pair[0].time, time_format)
                        end_time = datetime.strptime(pair[1].time, time_format)
                        return (end_time - start_time).total_seconds()
                    return None
                
                def get_duration_str(etype):
                    duration = get_duration(etype)
                    if duration is not None:
                        return f" - è€—æ—¶: {duration:.4f} ç§’"
                    return ""

                query_duration = get_duration(CBEventType.QUERY)
                if query_duration is not None:
                    st.info(f"**æ€»æŸ¥è¯¢è€—æ—¶: {query_duration:.4f} ç§’**")

                # æ­¥éª¤ 1: é—®é¢˜å‘é‡åŒ–
                embedding_events = [p for p in event_pairs if p[0].event_type == CBEventType.EMBEDDING]
                if embedding_events:
                    st.markdown("---")
                    st.subheader(f"ç¬¬ä¸€æ­¥: é—®é¢˜å‘é‡åŒ– (Embedding){get_duration_str(CBEventType.EMBEDDING)}")
                    st.markdown("ç³»ç»Ÿè°ƒç”¨ Embedding æ¨¡å‹ï¼Œå°†æ‚¨çš„æ–‡æœ¬é—®é¢˜è½¬æ¢æˆæœºå™¨å¯ä»¥ç†è§£çš„æ•°å­—åˆ—è¡¨ï¼ˆå‘é‡ï¼‰ã€‚")
                    query_text = embedding_events[0][1].payload.get(EventPayload.CHUNKS, ["æœªçŸ¥è¾“å…¥"])[0]
                    embedding_vector = embedding_events[0][1].payload.get(EventPayload.EMBEDDINGS, [[]])[0]
                    st.text_area("è¾“å…¥æ–‡æœ¬", value=query_text, height=100, disabled=True, key="embed_in")
                    st.text_area("è¾“å‡ºå‘é‡ (ä»…æ˜¾ç¤ºå‰5ä¸ªç»´åº¦)", value=str(embedding_vector[:5])+"...", height=100, disabled=True, key="embed_out")

                # æ­¥éª¤ 2: å‘é‡æ£€ç´¢
                retrieval_events = [p for p in event_pairs if p[0].event_type == CBEventType.RETRIEVE]
                if retrieval_events:
                    st.markdown("---")
                    st.subheader(f"ç¬¬äºŒæ­¥: å‘é‡æ£€ç´¢ (Retrieval){get_duration_str(CBEventType.RETRIEVE)}")
                    st.markdown('ç³»ç»Ÿä½¿ç”¨"é—®é¢˜å‘é‡"ï¼Œåœ¨ ChromaDB ä¸­æœç´¢è¯­ä¹‰æœ€ç›¸å…³çš„æ–‡æœ¬å—ã€‚')
                    retrieved_nodes = retrieval_events[0][1].payload.get(EventPayload.NODES, [])
                    if retrieved_nodes:
                        st.success(f"åœ¨æ•°æ®åº“ä¸­æˆåŠŸæ£€ç´¢åˆ° {len(retrieved_nodes)} ä¸ªç›¸å…³æ–‡æœ¬å—ã€‚")
                        for node_idx, node in enumerate(retrieved_nodes):
                            with st.container(border=True):
                                st.markdown(f"**æ–‡æœ¬å— {node_idx+1} (ç›¸ä¼¼åº¦: {node.score:.4f})**")
                                st.text_area(f"å†…å®¹ (Chunk ID: {node.metadata.get('chunk_id')})", value=node.get_content(), height=120, disabled=True, key=f"retrieved_{node_idx}")

                # æ­¥éª¤ 3: ç­”æ¡ˆç”Ÿæˆ
                synthesize_events = [p for p in event_pairs if p[0].event_type == CBEventType.SYNTHESIZE]
                if synthesize_events:
                    st.markdown("---")
                    st.subheader(f"ç¬¬ä¸‰æ­¥: ç­”æ¡ˆç”Ÿæˆ (LLM Synthesize){get_duration_str(CBEventType.SYNTHESIZE)}")
                    st.markdown('ç³»ç»Ÿå°†æ£€ç´¢åˆ°çš„æ–‡æœ¬å—ä½œä¸º"ä¸Šä¸‹æ–‡"ï¼Œè¿åŒåŸå§‹é—®é¢˜ç»„åˆæˆæœ€ç»ˆæç¤ºè¯ (Prompt)ï¼Œå‘é€ç»™å¤§è¯­è¨€æ¨¡å‹ (LLM) ç”Ÿæˆç­”æ¡ˆã€‚')
                    
                    llm_duration = get_duration(CBEventType.LLM)
                    if llm_duration is not None:
                        st.caption(f"å…¶ä¸­ï¼Œå¤§è¯­è¨€æ¨¡å‹è°ƒç”¨ (LLM) è€—æ—¶ {llm_duration:.4f} ç§’")

                    llm_events = [p for p in event_pairs if p[0].event_type == CBEventType.LLM]
                    if llm_events:
                        prompt_payload = llm_events[0][0].payload.get(EventPayload.PROMPT) or llm_events[0][0].payload.get(EventPayload.MESSAGES)
                        response_payload = llm_events[0][1].payload.get(EventPayload.RESPONSE) or llm_events[0][1].payload.get(EventPayload.LLM_RESPONSE)
                        
                        if prompt_payload:
                            full_prompt_str = "\n\n---\n\n".join([str(p) for p in prompt_payload]) if isinstance(prompt_payload, list) else str(prompt_payload)
                            st.text_area("å‘é€ç»™å¤§æ¨¡å‹çš„æœ€ç»ˆæç¤ºè¯ (Full Prompt)", value=full_prompt_str, height=400, disabled=True, key="prompt")
                        
                        if response_payload:
                            raw_response_str = str(getattr(response_payload, 'raw', response_payload))
                            st.text_area("ä»å¤§æ¨¡å‹æ”¶åˆ°çš„åŸå§‹å›å¤ (Raw Response)", value=raw_response_str, height=200, disabled=True, key="response")

    # å°†åŠ©æ‰‹çš„çº¯æ–‡æœ¬å›ç­”æ·»åŠ åˆ°å†å²è®°å½•
    if "response" in locals() and hasattr(response, 'response'):
        st.session_state.messages.append({"role": "assistant", "content": response.response})
    
    # æœ€åï¼Œé‡ç½®å…¨å±€å›è°ƒç®¡ç†å™¨
    Settings.callback_manager = CallbackManager([])
